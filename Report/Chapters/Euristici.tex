\chapter{Algoritmi euristici}\label{HEURISTIC}
In questo capitolo verranno trattati algoritmi euristici che non fanno uso di CPLEX. La necessità di non utilizzare CPLEX si ha per istanze con un elevato numero di nodi.\\
Per queste istanze la risoluzione del tableau attraverso CPLEX diventerebbe molto un'operazione molto onerosa per via dell'alto numero di variabili che verrano create e su cui verrà svolto il calcolo.\\
Attraverso gli algoritmi euristici, viene computata un'approssimazione della soluzione ottima e spesso però può essere sfruttata inizialmente dal risolutore CPLEX. Ad esempio questo può essere aggiunta prima della computazione, utilizzando la funzione \textit{CPXaddmipstarts()}, o ,se già definita, può essere modificata tramite \textit{CPXchgmipstarts()}.\\
Un algoritmo euristico, affinchè funzioni al meglio, deve essere composto da due fasi che si alternino:
\begin{itemize}
\item{\textbf{Intensificazione o raffinamento}\\
In questa fase la soluzione corrente viene migliorata fino al raggiungimento di un ottimo (locale o globale) nello spazio delle soluzioni.
}
\item{\textbf{Diversificazione}\\
Fase in cui la soluzione viene perturbata con una politica predefinita affinchè si allontani da un ottimo locale nello spazio delle soluzioni.
}
\end{itemize}


\section{Algoritmi di costruzione}\label{construction_alg}
Questa tipologia di algoritmi euristici è fondamentale per la computazione di una prima soluzione ammissibile del problema.
\subsection{Nearest Neighborhood}
Questo algoritmo è basato su un approccio di tipo greedy. L'algoritmo sceglie inizialmente un nodo generico tra quelli che compongono il grafo ed in seguito seleziona iterativamente degli archi del grafo, secondo il criterio enunciato nella seguente sezione.\\
In ciascuna iterazione vengono analizzati gli archi uscenti dal nodo selezionato all'iterazione precedente e viene aggiunto il ramo collega l'estremo più vicino. Il nuovo nodo raggiunto verrà impostato come punto di partenza nell'analisi dei costi dell'iterazione successiva (vedi Figura \ref{nearest_neighborhood}).
All'ultima iterazione viene selezionato invece l'arco che collega l'ultimo nodo visitato al nodo scelto randomicamente all'inizio dell'algoritmo.\\
Il problema di questo algoritmo è che in ogni iterazione viene selezionato esclusivamente il vertice più vicino a quello scelto precedentemente, senza però cercare di prevedere e migliorare la futura evoluzione del costo del tour, creato dall'algoritmo.\\
Come in Figura \ref{nearest_neighborhood}, la scelta dell'arco di costo minimo non implica che in seguito venga generata la soluzione ottima. La scelta del nodo iniziale è fondamentale in quanto una perturbazione della partenza genera un tour differente.\\
Definito \textbf{n} come il numero di nodi presenti nel grafo, si avranno quindi n soluzioni differenti, ottenute ciascuna attraverso l'applicazione dell'algoritmo partendo da una diversa scelta iniziale. In seguito tra queste possibli soluzioni, verrà selezionata quella di costo minore.\\
\begin{figure}[H] 
\begin{center} 
  \includegraphics[scale=0.4]{Images/nearest_neighborhood}\\ 
  \caption{\footnotesize{Esempio di esecuzione di Nearest Neighborhood.}}
  \label{nearest_neighborhood} 
\end{center} 
\end{figure}

\subsection{Heuristic Insertion}
L'algoritmo seguente usa un approcco simile al precedente ma prevede inizialmente la selezione di un ciclo a cui apportare modifiche, per ottenere una soluzione iniziale ammissibile del problema. Per definire il ciclo di partenza vengono utilizzati diversi metodi. Di seguito sono riportati i due più utilizzati:
\begin{itemize}
\item{\textbf{Selezione di due nodi}\\
Vengono scelti i due nodi più lontani tra loro nel grafo, o due nodi casuali, e vegonono collegati mediante i due possibili archi orientati.
}
\item{\textbf{Inizializzazione geometrica}\\
Nel caso in cui i nodi del grafo appartengano ad uno spazio bidimensionale, ne viene calcolata la convex-hull e questa viene utilizzata come ciclo di partenza.
}
\end{itemize}
Questa prima soluzione viene modificata iterativamente e per ogni coppia di nodi non appartenenti al ciclo \textbf{C}, restituito dall'iterazione precedente, viene calcolato l'extramileage $\Delta_h$ come segue:
$$\Delta_h = \underset{(a,b)\in C}{min} c_{ah}+c_{hb}-c_{ay}$$
con $c_{ij}=$ costo dell'arco che collega i a j (vedi Figura \ref{partial_cycle}).\\
Alla fine di ciascuna iterazione viene aggiunto nel grafo il nodo \textbf{k} che minimizza l'\textbf{extra-mileage} (vedi Figura \ref{insertion}):\\
$$k = arg\underset{h}{min}\Delta_{h}$$
\begin{figure}[H] 
\begin{center} 
  \includegraphics[scale=0.3]{Images/partial_cycle}\\ 
  \caption{\footnotesize{Parte del calcolo dell'extramileage del nodo \textbf{h}.}}
  \label{partial_cycle}
\end{center}
\end{figure}
\begin{figure}[H] 
\begin{center} 
  \includegraphics[scale=0.4]{Images/insertion}\\ 
  \caption{\footnotesize{Esempio dell'applicatione di Heuristic insertion.}}
  \label{insertion}
\end{center}
\end{figure}

\subsection{GRASP}
Il metodo Greedy Adaptive Search Procedure (GASP) è un approccio algoritmico che permette di aggiungere una componente aleatoria alla computazione deterministica del minimo di un insieme di valori.\\
Ad ogni iterazione dei due precedenti algoritmi di costruzione, invece di selezionare l'arco di costo minimo o l'extra-mileage minimo, vengono memorizzati i rami di costo minore e le scelte con extra-mileage minore.\\
Tra le possibili mosse salvate, ne viene scelta randomicamente una. Nel programma sviluppato, oltre ai precedenti algoritmi di costruzione, ne sono state impplementate anche delle varianti che fanno uso del GRASP. In questo caso sono state memorizzate le tre scelte migliori in ogni iterazione.\\
Tali varianti permettono di modificare aleatoriamente l'evoluzione del tour, in modo da evitare che, nelle ultime iterazioni dell'algoritmo, le scelte possibili siano legate esclusivamente ad elevati incrementi della funzione obiettivo.\\
Ciò evita ad esempio che nel Nearest Neighborhood possano esserci numerose scelte come l'ultima effettuata in Figura \ref{nearest_neighborhood}.\\
Nella Sezione \ref{Construction_perf}, vengono confrontati tramite performance profile, gli algoritmi precedentemente nominati.

\section{Algoritmi di raffinamento}
Una volta ottenuta una prima soluzione è necessario migliorarla per avvicinarsi il più possibile all'ottimo. Gli algoritmi utilizzati con questo scopo sono detti \textit{algoritmi di raffinamento}. Nel capitolo precedente sono già stati descritti due procedimenti di questo tipo, l'Hard Fixing e il Soft Fixing (vedi sottosezioni \ref{hard fixing} e \ref{soft fixing}). In questa sezione verranno invece analizzati algoritmi di raffinamento che non utilizzino funzioni messe a disposizione da CPLEX.

\subsection{Algoritmo di 2-ottimalità}
Nelle soluzioni restituite dagli algoritmi euristici di costruzione sono spesso presenti incroci tra coppie di rami. La loro presenza implica che la soluzione non è ottima, in quanto per le proprietà dei triangoli esisterà sempre una tour che eviti l'incrocio e che sia di costo minore (vedi Figura \ref{cross}). 
\begin{figure}[H] 
\begin{center} 
  \includegraphics[scale=0.5]{Images/triangle_property}
  \caption{\footnotesize{Non ottimalità di una soluzione con incroci.}}
  \label{cross}
\end{center}
\end{figure}
L'algoritmo di 2-ottimilità prende il nome dalla modalità utilizzata iterativamente per modificare la soluzione ricevuta in ingresso. In ogni iterazione viene individuato un incrocio tra due rami, appartenenti al tour. Gli estremi di tali archi vengono collegati in maniera differente. Complessivamente per ogni incrocio, viene effettutato uno scambio tra coppie di rami (2-opt move) in modo da ridurre ulteriormente il costo della soluzione restituita.\\
Nell'implementare tale algoritmo non è necessario individuare ciascun incrocio della soluzione di partenza ma è sufficiente analizzare tutte le coppie di rami presenti e verificare se, scambiandole con un'altra coppia ammissibile, si verifichi un miglioramento della funzione obiettivo.
\begin{figure}[H] 
\begin{center} 
  \includegraphics[scale=0.4]{Images/swap}\\ 
  \caption{\footnotesize{Esempio di eliminazione di un incrocio.}}
  \label{swap}
\end{center}
\end{figure}
Riferendosi alla figura \ref{swap}, un possibile miglioramento viene calcolato come segue:\\
$$\Delta = (c_{ac} + c_{bd}) - (c_{ad} + c_{bc})$$
e solo nel caso in cui $\Delta$ sia negativo, la sostituzione viene effettuata.\\
Applicando una 2-opt move al circuito attuale, viene generato un tour appartenente all'intorno di 2-ottimalità della precedente soluzione. Ripetendo iterativamente tale procedimento si raggiunge un ottimo locale, in cui non esistono più possibili miglioramenti della funzione obiettivo. Questo processo è rappresentato in Figura \ref{two_optimality}. 
\begin{figure}[H] 
\begin{center} 
  \includegraphics[scale=0.4]{Images/two_optimality}\\ 
  \caption{\footnotesize{Aggiornamento della soluzione nell'intorno di 2 ottimalità.}}
  \label{two_optimality}
\end{center}
\end{figure}
Poichè il calcolo del $\Delta$ avviene in tempo costante e deve essere fatto per ogni coppia di rami, il tempo complessivo per la computazione è $O(n^2)$, con $n$ nodi dell'istanza del problema.\\
Un procedimento analogo a tale algoritmo viene utilizzato anche nel Soft Fixing, in cui però la dimensione dell'intorno in cui cercare la nuova soluzione varia (vedi Figura \ref{local_exe}).\\
Nel programma sviluppato, è stata utilizzata questo algoritmo per rimuovere gli incroci all'interno del tour.
 
\subsection{Algoritmo di 3 ottimalità}
L'algoritmo di 3 ottimalità è analogo a quello analizzato nella sezione precedente, ma considera intorni di grandezza maggiore. In questo caso, quindi, due soluzioni nell'intorno differiscono per 3 rami. In Figura \ref{three_optimality} viene riportata la rappresentazione delle possibili 3-opt move.
\begin{figure}[H] 
\begin{center} 
  \includegraphics[scale=0.35]{Images/3_swap}
  \caption{\footnotesize{Tutte le possibili combinazioni di scambi di 3 ottimalità.}}
  \label{three_optimality}
\end{center}
\end{figure}
L'algoritmo impiega in tutto $O(n^3)$ (con $n$ numero di nodi) per trovare un ottimo locale, essendo $O(n^3)$ il numero di terne di rami esistenti e poichè il numero di possibili scambi di 3 ottimalità è costante. Su istanze con un elevato numero di nodi, il tempo di calcolo risulterebbe essere troppo lungo per il calcolo di una soluzione.\\
All'interno del programma sviluppato, non è stata implementato tale algoritmo.

\section{Meta-euristici}
Gli algoritmi di raffinamento appena visti si occupano di migliorare il più possibile una soluzione già calcolata attraverso meccanismi di local search. In questo modo, dopo un determinato numero di iterazioni, viene raggiunto un ottimo locale.\\
Gli algoritmi descritti in questa sezione perturbano la soluzione allontanandola dall'attuale ottimo locale e cercando di avvicinarsi il più possibile all'ottimo globale.\\
Questi metodi rappresentano approcci più generali di quelli descritti precedentemente e sono plasmabili e applicabili anche a problemi dfferenti rispetto al TSP. Tali tecniche infatti permettono essenzialmente di espolarare lo spazio delle soluzioni, evitando di stazionare in minimi o massimi locali con valori della funzione obiettivo molto lontani dall'ottimo globale.

\subsection{Multi-start}
Un primo e intuitivo approccio per allontanarsi da un ottimo locale è quello descritto dalla politica multi-start. Questa consiste nel definire diverse soluzioni attraverso un algoritmo di costruzione tra quelli descritti, ad esempio, nella Sezione \ref{construction_alg}. A ciascuno di esse viene poi applicato un algoritmo di raffinazione e viene scelta solo quella con costo migliore tra tutte le soluzioni generate. In questo modo vengono analizzati diversi ottimi locali nello spazio delle soluzioni (vedi Figura \ref{multi_start}. 
\begin{figure}[H] 
\begin{center} 
  \includegraphics[scale=0.5]{Images/multistart}\\ 
  \caption{\footnotesize{Due possibile esecuzioni di un algoritmo di raffinamento con partenze da due soluzioni diverse.}}
  \label{multi_start}
\end{center}
\end{figure}
Un lato negativo di tale approccio consiste nel fatto che ogni volta che viene scelta una nuova soluzione di partenza, vengono perse le informazioni relative alla sequenza ottenuta utilizzando un altro tour iniziale.\\
La soluzione implementata all'interno del programma è basata sul multithreading. Infatti viene generato un numero di soluzioni pari al numero di thread specificati.\\
Ciascun thread genera parallelamente agli altri una nuova soluzione e solo al termine della computazione, la confronta con la migliore. Nel caso in cui il costo della soluzione trovata sia inferiore a questa, la aggiorna. \\
Nella Sezione \ref{construction_perf} viene analizzato il costo ottenuto dalla nostra implementazione, utilizzando 12 thread e modificando l'algoritmo di costruzione utilizzato.

\subsection{Variable Neighborhood Search}
Una volta ottenuta una soluzione corrispondente ad un ottimo locale nella funzione di costo si può cercare di migliorarla analizzando i suoi intorni di ottimalità di raggio crescente. Questo però non garantisce un effettivo cambiamento della soluzione. Il Variable Neighborhood Search (VNS) è un algoritmo che sfrutta questa ricerca. Nel caso non si verifichi un aggiornamento della soluzione prevede che vengano scelti un certi numero di rami randomici da sostituire con altri non appartenenti alla soluzione, in maniera casuale \cite{VNS}. In questo modo si impone un aggiornamento con una crescita del costo, nella speranza che nel nuovo intorno selezionato sia possibile trovare una soluzione che si allontani dall'iniziale ottimo locale (Figura \ref{VNS_img}).\\
 \begin{figure}[H] 
\begin{center} 
  \includegraphics[scale=0.4]{Images/VNS}\\ 
  \caption{\footnotesize{Aggiornamento di una soluzione in un minimo locale.}}
  \label{VNS_img}
\end{center}
\end{figure}
L'algoritmo termina allo scadere del tempo a disposizione o dopo un determinato numero di iterazione, restituendo la miglior soluzione trovata fino a quel momento. Utilizzando questo approccio gran parte della soluzione di partenza viene conservata evitando di perdere le informazioni elaborate precedentemente all'utilizzo di VNS.\\
Per generare nuove istanze che appartengano all'intorno di k-ottimalità di una data soluzione, quest'ultima è stata codificata con un vettore di lunghezza pari al numero di nodi. Ogni cella di tale array contiene l'identificativo di un nodo e leggendo in ordine crescente di indice tale lista, si ottiene la sequenza di percorrenza dei nodi per tale soluzione. La generazione della nuova soluzione k-opt viene creata, scegliendo un indice \textbf{t} casuale dell'array, e permutando iterativamente due nodi nella sequenza, secondo il seguente algoritmo\cite{hybrid_VNS} e la Figura \ref{k_opt_move}.\\
\begin{algorithm}[H]
\DontPrintSemicolon
\KwIn {$\mathtt{x =\{x_1,x_2,...,x_n\}}$= soluzione di partenza\newline
$\mathtt{k}$= numero di archi da variare nella soluzione di partenza}
\KwOut {$\mathtt{y}$= nuova soluzione appertenente all'intorno di k-ottimalità di x}
\BlankLine
$\mathtt{y}=x$\;
$\mathtt{t \gets RANDOM(}\{1,...,n\}\mathtt{)}$\;
\BlankLine
 \For{$j \gets 1$ \KwTo $k-1$}{
  \BlankLine
  $\mathtt{swap(}y_t,y_{t+j}\mathtt{)}$;
 }
 \caption{Generazione di una soluzione randomica k-opt}
\end{algorithm}
\begin{figure}[H] 
\begin{center} 
  \includegraphics[scale=0.4]{Images/k_opt_move}\\ 
  \caption{\footnotesize{Generazione di una soluzione randomica k-opt.}}
  \label{k_opt_move}
\end{center}
\end{figure}

\subsection{Tabu search}%inserire nostra implementazione delle mosse vietate
L'approccio Tabu search fu ideato da Fred W. Glover \cite{Tabu}. Data una soluzione in un ottimo locale dello spazio delle soluzioni, l'idea di Glover permette di aggiornarla anche con una di costo più elevato (generalmente si cerca di minimizzare questo peggioramento). Per evitare che all'iterazione successiva si ritorni nella soluzione di partenza, viene creata una lista di "mosse vietate", detta Tabu list, che impedisca di raggiungere nuovamente l'ottimo locale. In questo modo la soluzione aumenta di costo per un certo numero di iterazioni, finchè non ricomincia a diminuire per raggiungere un nuovo minimo locale o globale. Nel caso in cui si incontri una soluzione che migliori l'incumbent senza rispettare tutti i vincoli presenti nella Tabu list, l'algoritmo aggiorna ugualmente la soluzione corrente. Questo meccanismo viene detto \textit{Aspiration criterion}.\\ 
Aumentando costantemente di dimensione la lista Tabu si rischia, ad un certo punto, che non sia più possibile aggiornare la soluzione. Per evitare ciò generalmente viene scelta una capienza massima (detta \textit{tenure}) della lista, una volta raggiunta la lista viene aggiornata rispettando la politica FIFO (first in first out). Per far si che l'algoritmo oscilli tra la fase di diversificazione e quella di intensificazione, la tenure viene fatta variare durante le diverse iterazioni tra due valori (massimo e minimo) (vedi Figura \ref{tenure}). Nelle iterazioni in cui è massima si verifica la diversificazione, in quelle in cui è minima l'intensificazione. Se viene applicata questa scelta implementativa l'algoritmo è chiamato \textit{Reactive Tabu Search}.
 \begin{figure}[H] 
\begin{center} 
  \includegraphics[scale=0.35]{Images/tenure}\\ 
  \caption{\footnotesize{Variazione della tenure.}}
  \label{tenure}
\end{center}
\end{figure}
Come per l'algoritmo precedente, il criterio di terminazione è dato dallo scadere del tempo a disposizione o dal raggiungimento del numero massimo di iterazioni scelto, restituendo la miglior soluzione trovata fino a quel momento.\\\\
\begin{algorithm}[H]
\DontPrintSemicolon
\KwIn{$\mathtt{x}$= soluzione di un'istanza di TSP corrispondente ad un ottimo locale\newline
$\mathtt{tenure}$= dimensione massima della Tabu List\newline
$\mathtt{deadline}$= time limit complessivo dell'algoritmo\newline
$\mathtt{num\_iterations}$= numero massimo di iterazioni\newline
$\mathtt{num\_nodi}$= numero di nodi dell'istanza tsp\newline}
\KwOut {$\mathtt{y}$= miglior soluzione trovata}
\BlankLine
$\mathtt{n}=0$\;
\BlankLine
\While{$n < num\_iterations \wedge\;\;'deadline\;not\;expired'$}{
 \BlankLine
 $\mathtt{x' \gets move\_random\_2opt(}x)$\;
 \BlankLine
 \BlankLine
\While{$(check\_tabu\_list(x') ==\;'valid\;move')$}{
  \BlankLine
  $\mathtt{x' \gets move\_random\_2opt(}x\mathtt{)}$\;
}
  $\mathtt{x} \gets x'$\;
  $\mathtt{add\_tabu\_list(}edges\_removed, tenure\mathtt{)}$\;
  \BlankLine
  \If{$cost(x') < cost(x)$}{
    \BlankLine
    $\mathtt{x \gets greedy\_refinement(}x, tabu\_list\mathtt{)}$\;
    \BlankLine  
  }
  \BlankLine
  $\mathtt{n \gets}n+1$\;
}
 \BlankLine
$\mathtt{y}= best\_solution()$\;
\caption{Tabu Search}
\end{algorithm}
\subsection{Simulated annealing}
L'algoritmo simulated annealign, come dice il nome, è ispirato dal processo di temperamento dei metalli, in cui il materiale viene raffreddato molto lentamente e in maniera controllata, affinchè raggiunga la configurazione di minima energia. Analogamente, in questo algoritmo viene scelta una funzione (generalmente esponenziale) che descriva la variazione della "temperatura" $T$. Ad ogni iterazione la soluzione corrente può essere aggiornata con una qualsiasi altra interna all'intorno di 2 ottimalità, di costo minore o maggiore, con una probabilità funzione della variazioni di costo e della temperatura attuale, $f(\Delta costo, T)$. Questo implica che non sia necessario scandire tutto l'intorno, ma che sia sufficiente scegliere in maniera randomica 2 rami da sostituire nella soluzione (Figura \ref{simulated_annealing}).
 \begin{figure}[H]
\begin{center} 
  \includegraphics[scale=0.43]{Images/simulated_anneling}
  \caption{\footnotesize{Esempio di esecuzione dell'algoritmo Simulated Annealing.}}
  \label{simulated_annealing}
\end{center}
\end{figure}
 Con il procedere delle iterazioni, l'aggiornamento ad un costo peggiore avviene sempre meno frequentemente, fino ad ottenere solo aggiornamenti con soluzioni più vantaggiose. Esiste un teorema secondo il quale se la temperatura varia in maniera estremamente lenta ed è consentito effettuare un numero di iterazioni estremamente elevato, questo algoritmo garantisce di trovare l'ottimo globale. Concretamente queste ipotesi sono molto difficili da realizzare, ma è statisticamente comunque possibile dichiarare che l'approccio del simulated annealing restituisce una buona soluzione.
\section{Algoritmo genetico}
L'algoritmo genetico è legato alla teoria dell'evoluzione di Darwin, con cui condivide numerosi concetti. Da un punto di vista teorico, l'algoritmo definisce in prima battuta una serie di individui, che costituiscono una popolazione.\\
In seguito, attraverso mutazioni dei singoli soggetti e la riproduzione di questi, si crea una nuova popolazione. Il concetto fondamentale alla base di tale algoritmo è che associando ad un individuo uno score, lo si possa utilizzare per far progredire la specie.\\
Ad ogni individuo viene associata una fitness, che rappresenta quanto sia forte ed efficiente. Applicando tale concetto al Travelling Salesman Problem, ad ogni individuo $i$ è stata associata una fitness pari a:
$$fitness_i=\frac{1}{costo_i}$$
dove $costo_i$ rappresenta il valore della funzione obiettivo per l'istanza $i$.\\
La popolazione iniaziale nell'algoritmo sviluppato, è stata generata utilizzando l'algoritmo nearest neighbour ma utilizzando un diverso nodo di partenza per ciascuno di essi. Ogni individuo della popolazione è stato rappresentato come la sequenza dei nodi, in ordine di visita.\\
In seguito vengono generati nuovi individui a partire dalla popolazione attuale, utilizzando due tecniche differenti:
\begin{itemize}
\item{\textbf{Crossover}\\
in questa operazione vengono selezionati randomicamente due individui della popolazione e partire da questi, vengono creati nuovi tour che ereditano dai genitori delle caratteristiche. Nel nostro caso ciascun individuo eredita parte della sequenza di visita di uno dei suoi genitori, e la restante parte viene ereditata dall'altro genitore.}
\item{\textbf{Mutazione}\\
in questa fase un certo numero di individui viene selezionato in maniera casuale e da ciascuno di questi, viene generato un nuovo tour attraverso una permutazione casuale della sequenza di partenza.}
\end{itemize}
L'utilizzo di tali tecniche iterativamente insieme alla rimozione dellla popolazione degli individui di costo peggiore, permette di ridurre complessivamente il costo medio delle istanze nella popolazione.\\
Riducendo tale valore medio della funzione obiettivo, si riesce ad ottenere una migliore soluzione con numerose iterazioni. All'interno del programma sviluppato, le precedenti tecniche non sono state applicate contemporaneamente in ogni iterazione ma in istanti differenti, secondo quanto descritto nel seguente algoritmo.\\

\begin{algorithm}[H]
\DontPrintSemicolon
\KwIn {$\mathtt{population}$= popolazione di numerosi tour generati mediante un algoritmo di costruzione\newline}
\KwOut {$\mathtt{y}$= sequenza di visita dei nodi nel tour ottenuto di costo minore}
\BlankLine
 $\mathtt{num\_epochs} \gets$ 0\;
 $\mathtt{best\_cost} \gets$ 0\;
 \BlankLine
 \While{$\mathtt{num\_epochs} < MAX\_NUM\_EPOCHS$}{
  \BlankLine  
  \If{$num\_epochs\;mod\;3 == 0$}{
     \BlankLine    
     $\mathtt{crossover(}population, best\_cost\mathtt{)}$\;
  }
  \Else{
     \BlankLine    
     $\mathtt{mutation(}population, best\_cost\mathtt{)}$\;
  }
  \BlankLine
  $\mathtt{remove\_worst\_members(}population{)}$\;
  \BlankLine
 }
 
 $\mathtt{y}\gets best_member(population)$
 \caption{Evoluzione}
\end{algorithm}
La fase di crossover viene applicata più di rado, poichè la generazione di nuovi figli a partire dai genitori richiede molto più tempo della creazione dello stesso numero di individui mediante mutazione.\\
Gli algoritmi di crossover e mutazione, utilizzati nel programma sviluppato, sono spiegati nella seguente sezione, con le relative illustrazioni.\\\\
\begin{algorithm}[H]
\DontPrintSemicolon
\KwIn {$\mathtt{population}$= popolazione di numerosi tour generati mediante un algoritmo di costruzione\newline
$\mathtt{sum\_fitnesses}$= somma delle fitness di tutti gli individui della popolazione \newline
$\mathtt{best\_cost}$= costo della migliore soluzione attuale\newline}
\KwOut {$\mathtt{offspring_1, offspring_2}$= nuovi individui generati nella popolazione\newline}
\BlankLine 
$\mathtt{n}$= numero di nodi dell'istanza tsp\;
$\mathtt{x=\{x_1,...,x_n\} \gets RANDOM(}population, p=\frac{fitness_x}{sum\_fitnesses})$\;
$\mathtt{y=\{y_1,...,y_n\} \gets RANDOM(}population, p=\frac{fitness_y}{sum\_fitnesses})$\;
 \BlankLine \BlankLine
 $\mathtt{offspring_1[1,...n/2]}=x[1,..., n/2]$\;
 $\mathtt{offspring_2[n/2+1,...,n]}=y[n/2+1,..., n]$\;
 $\mathtt{offspring_1[n/2+1,...,n]}=\{y_i\in y\; :\; y_i\not\in\{x_1, ..., x_{n/2}\}\}$\;
 $\mathtt{offspring_2[n/2+1,...,n]}=\{x_i\in x\; :\; x_i\not\in\{y_{n/2+1}, ..., y_{n}\}\}$\;
  \BlankLine
  $\mathtt{sum\_fitnesses\gets update(}sum\_fitness, offspring_1, offspring_2\mathtt{)}$\;
  \BlankLine  
  $\mathtt{min\_cost \gets min(}cost(offspring_1), cost(offspring_2)\mathtt{)}$\;  
  \BlankLine
  \If{$cost(offspring1) < best\_cost$}{
 	 $\mathtt{best\_cost} \gets min\_cost$\;
     \BlankLine
  }
\caption{Crossover}
\end{algorithm}

\begin{figure}[H]
\begin{center} 
  \includegraphics[scale=0.37]{Images/crossover}
  \caption{\footnotesize{Esempio di applicazione del crossover su due istanze x e y.}}
  \label{crossover}
\end{center}
\end{figure}

\begin{algorithm}[H]
\DontPrintSemicolon
\KwIn {$\mathtt{population}$= popolazione di numerosi tour generati mediante un algoritmo di costruzione\newline
$\mathtt{sum\_fitnesses}$= somma delle fitness di tutti gli individui della popolazione\newline
$\mathtt{best\_cost}$= costo della migliore soluzione attuale\newline}
\KwOut {$\mathtt{offspring1, offspring2}$= nuovo individuo generato nella popolazione}
\BlankLine
$\mathtt{n} \gets$ numero di nodi dell'istanza tsp\;
\BlankLine
$\mathtt{x=\{x_1,...,x_n\}\gets} RANDOM(population)$\;
 \BlankLine
 $\mathtt{begin} \gets RANDOM(\{1,...,n/2\})$\;
 $\mathtt{end} \gets RANDOM(\{n/2+1,...,n\})$\;  
 \BlankLine
 \For{$\mathtt{i}\gets begin$ \KwTo $end$}{
	\BlankLine
	$\mathtt{offspring[}i\mathtt{]}\gets x[end - i + begin]$\;
 }  
 
 \If{$cost(offspring) < best\_cost$}{
 	$\mathtt{best\_cost} \gets cost(offspring)$\;
 }
\caption{Mutazione}
\end{algorithm}

\begin{figure}[H]
\begin{center} 
  \includegraphics[scale=0.4]{Images/mutation}
  \caption{\footnotesize{Esempio di applicazione della mutazione su un'istanza x.}}
  \label{mutation}
\end{center}
\end{figure}

\begin{comment}
\section{Funzione di costo a scalini}
La funzione obiettivo di un problema può avere, in particolari circostanze, un grafico a scalini, in cui cioè esistano diverse soluzioni dell'istanza con lo stesso costo. In questo caso è consigliabile applicare una politica che utilizzi delle penalità per perturbare la funzione affinché non siano più presenti le zone costanti, che potrebbero causare problemi nell'aggiornamento della soluzione da restituire. Generalmente questa situazione non si verifica con istanze del problema del commesso viaggiatore in cui i costi dipendono dalla distanza euclidea. Nel caso fosse necessario, però, è possibile ammettere che l'algoritmo utilizzato per la risoluzione del problema, restituisca anche soluzioni con più componenti connesse. In questo modo sarebbe possibile scegliere una penalità dipendente dal numero di vincoli violati (ovvero dal numero di subtour presenti) che influenzi il costo della soluzione nel seguente modo:
$$costo\_totale = costo\_archi + M (num\_subtour -1)$$
con M variabile molto grande.
\end{comment}